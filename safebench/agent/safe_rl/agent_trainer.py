"""
 
Email: 
Date: 2023-02-16 11:20:54
LastEditTime: 2023-02-26 00:38:28
Description: 
"""

import time

from safebench.agent.safe_rl.rl_agent import WORKER_LIST


class AgentTrainer:
    def __init__(self, agent_config, logger):
        self.logger = logger
        self.verbose = agent_config["verbose"]
        self.epochs = agent_config["epochs"]
        self.evaluate_episode_num = agent_config["evaluate_episode_num"]
        self.save_freq = agent_config["save_freq"]
        self.policy_config = agent_config[agent_config["policy_name"]]
        self.worker_config = self.policy_config["worker_config"]
        self.worker_config["ego_action_dim"] = agent_config["ego_action_dim"]
        self.worker_config["ego_state_dim"] = agent_config["ego_state_dim"]
        self.worker_config["obs_type"] = agent_config["obs_type"]
        self.worker = WORKER_LIST[agent_config["policy_name"]](
            self.worker_config, self.logger
        )
        self.env = None
        self.agent_policy = None
        self.scenario_policy = None
        self.data_loader = None
        self.replay_buffer = None

    def set_environment(
        self, env, data_loader, replay_buffer, agent_policy, scenario_policy
    ):
        self.env = env
        self.data_loader = data_loader
        self.replay_buffer = replay_buffer
        self.agent_policy = agent_policy
        self.scenario_policy = scenario_policy
        self.worker.set_environment(
            env, data_loader, replay_buffer, agent_policy, scenario_policy
        )

    def train(self):
        continue_from_epoch = self.agent_policy.load_itr
        if continue_from_epoch is None:
            continue_from_epoch = 0
        start_time = time.time()
        total_steps = 0
        for epoch in range(continue_from_epoch, self.epochs):
            epoch_steps = self.worker.train_one_epoch(epoch, self.epochs)
            total_steps += epoch_steps

            for _ in range(self.evaluate_episode_num):
                self.worker.eval()

            if hasattr(self.agent_policy, "post_epoch_process"):
                self.agent_policy.post_epoch_process()

            # Save model
            if (epoch % self.save_freq == 0) or (epoch == self.epochs - 1):
                self.logger.save_state({"env": None}, None)

            # Log info about epoch
            self.data_dict = self._log_metrics(
                epoch, total_steps, time.time() - start_time, self.verbose
            )

    def _log_metrics(self, epoch, total_steps, time=None, verbose=True):
        self.logger.log_tabular("Epoch", epoch)
        self.logger.log_tabular("TotalStep", total_steps)
        for key in self.logger.logger_keys:
            self.logger.log_tabular(key, average_only=True)
        if time is not None:
            self.logger.log_tabular("Time", time)
        # data_dict contains all the keys except Epoch and TotalEnvInteracts
        data_dict = self.logger.dump_tabular(
            x_axis="TotalStep",
            verbose=verbose,
        )
        return data_dict
